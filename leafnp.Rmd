---
title: "Leaf N and P analysis"
author: "Beni Stocker"
date: "1/6/2021"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(readr)
library(purrr)
library(rbeni)
library(ingestr)
```

## Read data

File without environmental covariates.
```{r}
df <- read_csv("~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210224.csv") %>%  #, col_types = "idddcccdddddccccccc") %>%   # file without covariates
  rename(lon = lon_estimate,
         lat = lat_estimate,
         elv = Alt_Di_check_final) %>% 
  rename(year_start = Sampling_Year_start,
         year_end = Sampling_Year_end) %>% 
  
  ## to be done: make sampling year info machine readable: either in the form of "9999" or "8888_9999"
  separate(Sampling_Month, sep = "_", c("month_start", "month_end")) %>% 
  mutate(month_start = as.numeric(month_start), month_end = as.numeric(month_end)) %>% 
  
  ## arrange by year
  arrange(year_start) %>% 
  
  ## create identifier
  mutate(id = paste0("i", seq(nrow(.))))

## save with added ids and site names
write_csv(df, file = "~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210702_PROC.csv")

## look at some distributions
df %>% 
  ggplot(aes(x = leafN, y = ..density..)) +
  geom_histogram()

df %>% 
  ggplot(aes(x = leafP, y = ..density..)) +
  geom_histogram()
```

### Complement missing elevation

```{r}
# df <- read_csv("~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210702_PROC.csv")

df_tmp <- df %>% 
  dplyr::filter(is.na(elv)) %>% 
  distinct(lon, lat) %>% 
  mutate(sitename = paste0("i", seq(nrow(.))))

## extract elevation data from etopo1
df_etopo <- ingest(
  df_tmp,
  source = "etopo1",
  dir = "~/data/etopo/"  # adjust this with your local path
  ) %>% 
  unnest(data) %>% 
  
  ## add it again so it has lon and lat
  right_join(df_tmp, by = "sitename") %>% 
  ungroup() %>% 
  rename(elv_etopo = elv) %>% 
  dplyr::select(-sitename)
  
## add etopo elevation data to data frame
df <- df %>% 
  left_join(df_etopo, by = c("lon", "lat")) %>% 
  rowwise() %>% 
  mutate(elv = ifelse(is.na(elv), elv_etopo, elv)) %>% 
  dplyr::select(-elv_etopo) %>% 
  
  ## create new variable site name (sometimes multiple obs are available for one site)
  mutate(sitename = paste0("i_", as.character(lon), "_", as.character(lat), "_", as.character(elv)))

## save with complemented elevation
write_csv(df, file = "~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210702_PROC_ELV.csv")
```

## Identify sites

Identify sites (unique lon, lat, elevation)

```{r}
# df <- read_csv("~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210702_PROC_ELV.csv")

df_sites <- df %>%
  distinct(sitename, lon, lat, elv)

## determine start and end year for each site based on available measurements
df_sites <- df %>% dplyr::select(sitename, year_start, year_end) %>% 
  group_by(sitename) %>% 
  summarise(year_start = min(year_start, na.rm = TRUE),
            year_end   = max(year_end, na.rm = TRUE)) %>% 
  right_join(df_sites, by = "sitename")

write_csv(df_sites, file = "~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/df_sites_leafnp_20210702.csv")
write_csv(df_sites, file = "data/df_sites_leafnp_20210702.csv")
```

## Data overview

### Observations per species

How many observations per species?

```{r}
df %>% 
  group_by(Species) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

## number of data points with species that have at least 5 observations: 23513
use_species <- tmp %>% 
  dplyr::filter(count >= 5) %>% 
  pull(Species)
df %>% 
  dplyr::filter(Species %in% use_species) %>% 
  nrow()
```

### Observations per genus

How many observations per genus?

```{r}
tmp <- df %>% 
  group_by(Genus) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

tmp
```

### Observations per family

How many observations per family?

```{r}
tmp <- df %>% 
  group_by(Family) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

tmp
```

### Site distribution

Sites on a global map

```{r}
plot_map_simpl() +
  geom_point(data = df_sites, aes(x = lon, y = lat), color = "red", size = 0.3)
```

<!-- ## Identify cells -->

<!-- Based on half-degree global grid. ACTUALLY NOT NEEDED. -->

<!-- ```{r eval=FALSE} -->
<!-- ## bin to half-degree gridcells for determining climate forcing -->
<!-- dlon <- 2 -->
<!-- dlat <- 2 -->
<!-- lon_breaks <- seq(from = floor(min(df_sites$lon)), to = ceiling(max(df_sites$lon)), by = dlon) -->
<!-- lat_breaks <- seq(from = floor(min(df_sites$lat)), to = ceiling(max(df_sites$lat)), by = dlat) -->

<!-- df_sites <- df_sites %>% -->
<!--   ungroup() %>%  -->
<!--   mutate(ilon = cut(lon,  -->
<!--                     breaks = lon_breaks -->
<!--                     ), -->
<!--          ilat = cut(lat,  -->
<!--                     breaks = lat_breaks -->
<!--                     ) -->
<!--          ) %>%  -->
<!--   mutate(lon_lower = as.numeric( sub("\\((.+),.*", "\\1", ilon)), -->
<!--          lon_upper = as.numeric( sub("[^,]*,([^]]*)\\]", "\\1", ilon) ), -->
<!--          lat_lower = as.numeric( sub("\\((.+),.*", "\\1", ilat) ), -->
<!--          lat_upper = as.numeric( sub("[^,]*,([^]]*)\\]", "\\1", ilat) ) -->
<!--          ) %>%  -->
<!--   mutate(lon_mid = (lon_lower + lon_upper)/2, -->
<!--          lat_mid = (lat_lower + lat_upper)/2) %>%  -->

<!--   ## create cell name to associate with climate input -->
<!--   mutate(cellname = paste0("icell_", as.character(lon_mid), "_", as.character(lat_mid))) %>%  -->
<!--   dplyr::select(-ilon, -ilat, -lon_lower, -lon_upper, -lat_lower, -lat_upper) -->

<!-- write_csv(df_sites, file = "data/df_sites_leafnp.csv") -->

<!-- df_cells <- df_sites %>%  -->
<!--   dplyr::select(cellname, lon_mid, lat_mid) %>%  -->
<!--   distinct() -->

<!-- write_csv(df_cells, file = "data/df_cells_leafnp.csv") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- ## sample one site per cell -->
<!-- df_sites_sampled <- df_sites %>%  -->
<!--   dplyr::select(sitename, lon, lat, elv, cellname) %>% -->
<!--   group_by(cellname) %>%  -->
<!--   sample_n(1) -->

<!-- plot_map_simpl() + -->
<!--   geom_point(data = df_sites_sampled, aes(x = lon, y = lat), color = "red", size = 0.3) -->
<!-- ``` -->

## Complement dataset

*Look into:*

-   Complement dataset with data points where only Nmass or only Pmass is available (no strict requirement to have paired Nmass and Pmass for this analysis).
-   Information about species identity, family, genus

### HWSD Soil

Read HWSD for each site. This reads all variables available fro HWSD. Select relevant variables in a separate step.

```{r eval=FALSE}
# df_sites <- read_csv("data/df_sites_leafnp_20210702.csv")

filn <- "data/df_hwsd_20210324.RData"
if (!file.exists(filn)){
  df_hwsd <- ingest(
    df_sites,
    source = "hwsd",
    settings = list(fil = "~/data/hwsd/HWSD_RASTER/hwsd.bil")
    )
  
  ## for some it got info for multiple soil types - take only first ones => TEST INFLUENCE OF THIS
  df_hwsd <- df_hwsd %>% 
    mutate(n_row = purrr::map_int(data, ~nrow(.))) %>% 
    mutate(data = purrr::map(data, ~slice(., 1)))
  
  df_hwsd <- df_hwsd %>% 
    dplyr::select(-n_row) %>% 
    unnest(data) %>% 
    dplyr::select(sitename, T_BULK_DENSITY, AWC_CLASS, T_CLAY, T_SILT, T_SAND, T_GRAVEL, T_PH_H2O, T_TEB, T_BS, T_CEC_SOIL, T_CEC_CLAY, T_ECE, T_ESP, T_CACO3, T_OC)
  
  save(df_hwsd, file = filn)
  
} else {
  load(filn)
}
```


### WISE30sec Soil

Define all variables to be extracted from WISE30sec

```{r}
settings_wise <- get_settings_wise(
  varnam = c("ORGC", "TOTN", "CNrt", "ALSA"),
  layer = 1:2
  )

df_wise <- ingest(
  df_sites,
  source    = "wise",
  settings  = settings_wise,
  dir       = "~/data/soil/wise"
  ) %>% 
  unnest(data)  # to get a normal flat table

save(df_wise, file = "data/df_wise_20210702.RData")
```


### GSDE

Define all variables to be extracted from GSDE. This is not using ingestr.

```{r}
df_sites <- read_csv("data/df_sites_leafnp_20210702.csv")

settings_gsde <- list(varnam =  c("PBR", "PHO", "TP", "TK", "TS"), layer = 1:4)

df_gsde <- ingest(
  df_sites,
  source    = "gsde",
  settings  = settings_gsde,
  dir       = "~/data/soil/shangguan"
  ) %>% 
  unnest(data)

save(df_gsde, file = "data/df_gsde_20210408.RData")
```


<!-- ### SoilGrids -->

<!-- Define all variables to be extracted from SoilGrids -->

<!-- ```{r} -->
<!-- settings_soilgrids <- get_settings_soilgrids( -->
<!--   varnam = c("nitrogen", "cec"), # xxx please adjust -->
<!--   layer = 1:3                    # xxx please adjust -->
<!--   ) -->
<!-- ``` -->

<!-- Get and save data. -->

<!-- ```{r} -->
<!-- df_sites <- read_csv("data/df_sites_leafnp.csv") -->
<!-- df_soilgrids <- ingest( -->
<!--   df_sites, -->
<!--   source    = "soilgrids", -->
<!--   settings  = settings_soilgrids -->
<!--   ) %>%  -->
<!--   unnest(data)  # to get a normal flat table -->

<!-- save(df_soilgrids, file = "data/df_soilgrids_leafnp.RData") -->
<!-- ``` -->


### Topography index

```{r}
filn <- "data/df_gti_20210702.RData"
if (!file.exists(filn)){
  rasta <- raster::raster("~/data/gti_marthews/ga2.nc")
  df_gti <- raster::extract(rasta, sp::SpatialPoints(dplyr::select(df_sites, lon, lat) %>% distinct()), sp = TRUE) %>%
    as_tibble() %>% 
    rename(gti = GDAL.Band.Number.1) %>% 
    right_join(df_sites, by = c("lon", "lat"))
  save(df_gti, file = filn)
} else {
  load(filn)
}
```

### CO2

Read CO2 level as the global mean and a mean over all the years over which sampling was done. This means that if we have replicate measurements for a given species at a given site, the measurements are given the same CO2 level. This assumes that replicates are not intended to cover a time period over which the environment changes.

```{r}
df_co2 <- ingest(
    df_sites,
    source  = "co2_cmip",
    verbose = FALSE,
    dir = "~/data/co2/"
  ) %>% 
  
  ## aggregate over years per site
  mutate(co2 = purrr::map_dbl(data, ~{summarise(., co2 = mean(co2)) %>% pull(co2)})) %>% 
  dplyr::select(-data)

save(df_co2, file = "data/df_co2_20210702.RData")
```

### Nitrogen deposition

Read N deposition from Lamarque et al. (2011) as NOx and NOy in gN m$^{-2}$ yr$^{-1}$ for respective year and location (based on half-degree input file).

```{r}
filn <- "data/df_ndep_20210702.RData"
if (!file.exists(filn)){
  df_ndep <- ingest(
    df_sites %>% 
      mutate(year_start = ifelse(year_start > 2009, 2009, year_start),
             year_end = ifelse(year_end > 2009, 2009, year_end)),    
    source    = "ndep",
    timescale = "y",
    dir       = "~/data/ndep_lamarque/",
    getvars   = c("nhx", "noy"),
    verbose   = FALSE
    )
  save(df_ndep, file = filn)
} else {
  load(filn)
}

## take sum of noy and nhx and aggregate over years
df_ndep_agg <- df_ndep %>% 
  mutate(data = purrr::map(data, ~mutate(., ndep = noy + nhx))) %>% 
  mutate(data = purrr::map(data, ~summarise(., ndep = mean(ndep, na.rm = TRUE)))) %>% 
  unnest(data)

save(df_ndep_agg, file = "data/df_ndep_20210702.RData")
```

### P-model outputs and climate indeces

The script `rscript_ingest_run_rsofun.R` is used to collect forcing data and run P-model simulations for all sites (N = 2149). Outputs are aggregated by site (annual mean of Vcmax25 and Jmax25, weighted by daily GPP). This also runs the function `R/calc_climate_index.R` on collected climate forcing data to return climate indeces (some of which are complementary to what is collected directly from WorldClim). The output is on Euler and is read here.
```{r}
read_pmodel <- function(path){
  load(path)
  return(df_pmodel)
}
df_pmodel <- purrr::map_dfr(as.list(list.files("data", pattern = "df_pmodel.*.RData", full.names = TRUE)),
                            ~read_pmodel(.))
```


## Combine all data

```{r}
load("data/df_ndep_20210702.RData") # loads df_ndep_agg
load("data/df_co2_20210702.RData") # df_co2
load("data/df_gti_20210702.RData") # loads df_gti
load("data/df_gsde_20210702.RData") # df_gsde
load("data/df_wise_20210702.RData") # df_wise
load("data/df_hwsd_20210702.RData") # df_hwsd

df <- read_csv("~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/global_leaf_NP_total_Di_20210702_PROC.csv")

df_my <- df %>% 
  left_join(df_wise, by = "sitename") %>% 
  left_join(df_hwsd, by = "sitename") %>% 
  left_join(df_gti %>% dplyr::select(-year_start, -year_end, -elv, -lon, -lat), by = "sitename") %>% 
  left_join(df_ndep_agg, by = "sitename") %>% 
  left_join(df_co2, by = "sitename") %>% 
  left_join(df_pmodel, by = "sitename")

## data prepared by di
df_di <- read_csv("~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/soil_property_extraction_20210323/global_leaf_NP_with_soil_property_from_HWSD_WISE_GSDE_23032021.csv")

## add my extractions to di's soil stuff
df_di <- df_di %>% 
  left_join(df_gti %>% dplyr::select(-year_start, -year_end, -elv, -lon, -lat), by = "sitename") %>% 
  left_join(df_ndep_agg, by = "sitename") %>% 
  left_join(df_co2, by = "sitename") %>% 
  left_join(df_pmodel, by = "sitename")

write_csv(df_di, "~/data/LeafNP_tiandi/Global_total_leaf_N_P_Di/soil_property_extraction_20210323/global_leaf_NP_with_soil_property_from_HWSD_WISE_GSDE_Pmodel_Ndep_GTI_CO2_25032021.csv")  

dim(df_my)
dim(df_di)
dim(df)

names(df_my)

## are my extractions and the one of di the same?
## yes
df_my %>% 
  dplyr::select(sitename, T_CACO3_beni = T_CACO3) %>% 
  left_join(dplyr::select(df_di, sitename, T_CACO3_di = T_CACO3), by = "sitename") %>% 
  rbeni::analyse_modobs2("T_CACO3_beni", "T_CACO3_di", type = "hex")

## yes
df_my %>% 
  dplyr::select(sitename, T_PH_H2O_beni = T_PH_H2O) %>% 
  left_join(dplyr::select(df_di, sitename, T_PH_H2O_di = T_PH_H2O), by = "sitename") %>% 
  rbeni::analyse_modobs2("T_PH_H2O_beni", "T_PH_H2O_di", type = "hex")

df_my %>% 
  dplyr::select(sitename, CNrt_beni = CNrt) %>% 
  left_join(dplyr::select(df_di, sitename, CNrt_di = CNrt), by = "sitename") %>% 
  rbeni::analyse_modobs2("CNrt_beni", "CNrt_di", type = "hex")
```

### Extracting from global NetCDF files

This is a code example and is to be used for extracting AI, alpha, and CWDX40 (see [here](https://www.notion.so/computationales/4e2e0ca6b5d3497894c64bed71a4937d?v=0ee5d81cd0fe42ac8ac1ed0a938b3380)).

Use the following files:

-   `~/data/mct_data/cwdx40.nc` for CWDX40.
-   `~/data/sofun_outputs/global_FULL_MODIS-C006_MOD15A2_v3.4/global_FULL_MODIS-C006_MOD15A2_v3.4.a.alpha_MEANANN.nc` for alpha.

```{r}
library(raster)

filn <- "~/data/mct_data/cwdx40.nc"
siteinfo <- tibble(sitename = "id1", lon = 100, lat = 50)  # example for required dataframe structure

## using raster package
rasta <- raster::raster(filn)  # use raster::brick() if data has three dimensions
df <- raster::extract(
    rasta,
    sp::SpatialPoints(dplyr::select(siteinfo, lon, lat)), # , proj4string = sta@crs
    sp = TRUE
    ) %>%
  as_tibble()

## or simply using rbeni
df <- rbeni::extract_pointdata_allsites(filn, df_lonlat = siteinfo)
```
